Nowadays, small quadrotors with on-board stabilization like the Parrot AR.Drone can be bought off-the-shelf.
These quadrotors make it possible to shift the research from basic control of the platform towards applications that make use of their versatile scouting capabilities. Possible applications are surveillance, inspection and search \& rescue. Still, the limited sensor suite and the fast movements make it quite a challenge to fully automate the navigation for such platforms. One of the prerequisites for autonomous navigation is the capability to make a map of the environment. 

The paper proceeds as follows. 
In Section 2 we give a short overview of related work.
Section 3 describes our methods.
First the simulation model of the AR.Drone is outlined in Section \ref{sec:simulation_model}.
Section \ref{sec:EKF} describes how the AR.Drone's pose can be estimated.
%The inertia measurements give mainly velocity information.
%An Extended Kalman Filter is used to integrate other sources of information to give a reasonable estimate of the pose.
This pose is used to build two visual maps: a texture map (Section \ref{sec:texture_map}) and a feature map (Section \ref{sec:feature_map}).
The texture map is used for human navigation and the feature map can be used to localize the AR.Drone (Section \ref{sec:localization}).
%In the results section (\ref{sec:results}) is demonstrated how well the localization works for circumstances encountered during the IMAV competition. 
We present experiments and results in Section 4.
This section demonstrates how well the localization works for circumstances encountered during the IMAV competition. 
%The paper concludes in Section 5.
Conclusions and future work are covered in Section 5 and 6.
% reference to future work?

	\section{Versatile scouting capabilities of a quadrotor helicopter}
	\section{International Micro Air Vehicle Competition}
	\section{Robocup Rescue}

	\section{Objectives and research questions}
An important goal of robotics is to develop mobile robots that can operate fully autonomously in real world situations.
One of the main prerequisites of an autonomous robot is the ability to known its location and movement in the environment.
Since no assumptions can be made about the environment, the robot has to learn from its environment.

Localization and mapping using aerial vehicles is an active research area in robotics.
However, current approaches use estimation and optimization algorithms that are computationally expensive and cannot be applied for realtime navigation problems.
Furthermore, other researchers rely on expensive aerial vehicles equipped with advanced sensors (e.g., laser range finder).
Focusing on realtime methods and cheap aerial vehicles increases the employability of aerial vehicles in the real world situations.
In case of semi-autonomous robots, building and visualizing a textured map of the invironment offers additional feedback to the teleoperator of the vehicle.

The main research question therefore is to determine a realtime localization and mapping approach that can be used for aerial vehicles with a low-resolution down-pointing camera (e.g., AR.Drone).

\begin{itemize}
\item Is a very low-resolution camera sufficient for localization against a map?
\item Is localization on regular basis possible for circumstances encountered during the IMAV competition?
\end{itemize}


	%\section{Contributions}
	\section{Outline}